# Chapter 5: Dimensionality reduction techniques

*In this chapter, we will practice dimensionality reduction techniques with example data.*

Let's start by reading in the data. The data consists of 9 variables of which only exp_educ is relatively normally distributed. The rest of them are skewed in one way or another. The strongest correlation is between exp_life and exp_educ, indicating that in countries where more people have a secondary education, the life expectancy is higher.

```{r}
# read in the data 
human <- read.csv("C:/Users/koivusus/IODS/IODS-project_new/data/human.csv")

# inspect the data 
head(human)

# remove X column 
human <- dplyr::select(human, -X)

# move the country names to rownames 
library(tibble)
human1 <- column_to_rownames(human, "Country")

# show a graphical overview 
library(GGally) 
ggpairs(human1, progress = FALSE)

# show summaries 
summary(human1)
```

Let's perform a principal component analysis (PCA) on the raw (non-standardized) human data, and show the variability captured by the principal components in percentages. 

Let's draw a biplot displaying the observations by the first two principal components (PC1 coordinate in x-axis, PC2 coordinate in y-axis), along with arrows representing the original variables.

```{r}
# perform principal component analysis (with the SVD method)
pca_human1 <- prcomp(human1)

# save summary in an object 
s <- summary(pca_human1)

# show variability captured by the principal components as rounded percentanges of variance captured by each PC
pca_pr <- round(1*s$importance[2, ], digits = 5)

# print out the percentages of variance
print(pca_pr)

# create object pc_lab to be used as axis labels
pc_lab <- paste0(names(pca_pr), " (", pca_pr, "%)")

# draw a biplot
biplot(pca_human1, cex = c(0.8, 1), col = c("grey40", "deeppink2"), xlab = pc_lab[1], ylab = pc_lab[2])
```

Let's standardize the variables in the human data and repeat the above analysis. 

Looks like the results from raw data vs. standardized data differ from each other quite a lot. In the raw data, the first component takes almost all of the variation, whereas in the standardized data, the variation is split between multiple components. 

*Interpret the results of both analysis (with and without standardizing). Are the results different? Why or why not? Include captions (brief descriptions) in your plots where you describe the results by using not just your variable names, but the actual phenomena they relate to. (0-4 points)*

*4. Give your personal interpretations of the first two principal component dimensions based on the biplot drawn after PCA on the standardized human data. (0-2 points)*

```{r}
# standardize the variables
human_std <- scale(human1)

# perform principal component analysis (with the SVD method)
pca_human_std <- prcomp(human_std)

# save summary in an object 
s_std <- summary(pca_human_std)

# show variability captured by the principal components as rounded percentanges of variance captured by each PC
pca_pr_std <- round(1*s_std$importance[2, ], digits = 5)

# print out the percentages of variance
print(pca_pr_std)

# create object pc_lab to be used as axis labels
pc_lab_std <- paste0(names(pca_pr_std), " (", pca_pr, "%)")

# draw a biplot
biplot(pca_human_std, cex = c(0.8, 1), col = c("grey40", "deeppink2"), xlab = pc_lab_std[1], ylab = pc_lab_std[2])

```

Let's download the tea data from the FactoMineR package and convert its character variables to factors. It is a questionnaire on tea: 300 individuals were asked how they drink tea and what are their product's perception. In addition, some personal details were asked.

```{r}
# load the tea dataset and convert its character variables to factors 
tea <- read.csv("https://raw.githubusercontent.com/KimmoVehkalahti/Helsinki-Open-Data-Science/master/datasets/tea.csv", stringsAsFactors = TRUE)

```

Let's explore the data briefly by looking at the structure and the dimensions of the data, viewing its contents and visualizing it. 

```{r}
# explore structure 
str(tea)

# explore dimensions
dim(tea)

# view the data
View(tea)

# load libraries 
library(dplyr)
library(tidyr)

# select columns to plot (otherwise there are too many to show in one plot)
tea_time <- dplyr::select(tea, Tea, How, how, sugar, where, lunch)

# visualize the dataset
library(ggplot2)
pivot_longer(tea_time, cols = everything()) %>% 
  ggplot(aes(value)) + geom_bar() + facet_wrap("name", scales = "free") + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
```

Let's use Multiple Correspondence Analysis (MCA) on the tea data. 

*Interpret the results of the MCA and draw at least the variable biplot of the analysis. You can also explore other plotting options for MCA. Comment on the output of the plots. (0-4 points)*

```{r}
# multiple correspondence analysis
library(FactoMineR)
mca <- MCA(tea_time, graph = FALSE)

# summary of the model
summary(mca)

# visualize MCA
plot(mca, invisible=c("ind"), graph.type = "classic", habillage = "quali")
```
