# Chapter 6: Analysis of longitudinal data 

*In this chapter, we will practice analysing longitudinal data.*

Longitudinal data, where a response variable is measured on each subject on several different occasions poses problems for their analysis because the repeated measurements on each subject are very likely to be correlated rather than independent. In PART I we will familiarize ourselves with longitudinal data and in PART II we will discuss methods for dealing with longitudinal data which aim to account for the correlated nature of the data and where the response is assumed to be normally distributed.


## PART 1: RATS data 

We will use data from a nutrition study conducted in three groups of rats. The groups were put on different diets, and each animalâ€™s body weight (grams) was recorded repeatedly (approximately) weekly, except in week seven when two recordings were taken) over a 9-week period. The question of most interest is whether the growth profiles of the three groups differ.

Lets start by reading in the data, converting the categorical variables to factors.

```{r}
# read in data 
RATS <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/MABS/master/Examples/data/rats.txt", header = TRUE, sep = '\t')

# load library
library(dplyr)

# convert categoricals to factors
RATS$ID <- factor(RATS$ID)
RATS$Group <- factor(RATS$Group)

# convert from wide to long 
RATSL <- pivot_longer(RATS, cols = -c(ID, Group), 
                      names_to = "groups",
                      values_to = "wd") %>% 
  mutate(Time = as.integer(substr(groups, 3, 4))) %>%
  arrange(Time)

# take a glimpse at the data
glimpse(RATSL)
```

Let's visualize the data. From this plot we can see that the body weight of rat individuals increases and the variability between rat individuals decreases over the nine weeks time. We can also see that rats who have higher body weight at the beginning tend to have higher values throughout the study (tracking phenomenon). 

```{r}
# load library
library(ggplot2)

# draw the plot
ggplot(RATSL, aes(x = Time, y = wd, linetype = ID)) +
  geom_line() +
  scale_linetype_manual(values = rep(1:10, times = 4)) +
  facet_grid(. ~ Group, labeller = label_both) +
  theme(legend.position = "none") + 
  scale_y_continuous(limits = c(min(RATSL$wd), max(RATSL$wd)))
```

Let's standardize the data to see the tracking phenomenon more clearly. 

```{r}
# load library
library(dplyr)
library(tidyr)

# standardize the variable wd
RATSL <- RATSL %>%
  group_by(Time) %>%
  mutate(stdwd = wd) %>%
  ungroup()

# plot again with the standardized wd
ggplot(RATSL, aes(x = Time, y = stdwd, linetype = ID)) +
  geom_line() +
  scale_linetype_manual(values = rep(1:10, times = 4)) +
  facet_grid(. ~ Group, labeller = label_both) +
  scale_y_continuous(name = "standardized wd")
```

Let's produce a graph showing average (mean) profiles for each treatment group along with the standard error of mean (= indication of the variation of the observations at each time point). Looks like the variation between rat individuals is smallest in group 1 and largest in group 3. 

```{r}
# set the number of subjects per group
n <- table(RATSL$Group)

# summary data with mean and standard error of bprs by treatment and week 
RATSS <- RATSL %>%
  group_by(Group, Time) %>%
  summarise(mean = mean(wd), se = parameters::standard_error(wd)) %>% 
  ungroup()

# plot the mean profiles
ggplot(RATSS, aes(x = Time, y = mean, linetype = Group, shape = Group)) +
  geom_line() +
  scale_linetype_manual(values = c(1, 2, 3)) +
  geom_point(size = 3) +
  scale_shape_manual(values = c(1, 2 ,3)) +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se, linetype = "1"), width = 0.3) +
  scale_y_continuous(name = "mean(wd) +/- se(wd)")
```

Let's calculate a summary measure (mean of weeks 1 to 9) and use it to further inspect the data. 

```{r}
# create a summary data by treatment and subject with mean as the summary variable (ignoring baseline week 1)
RATSL9S <- RATSL %>%
  filter(Time > 1) %>%
  group_by(Group, ID) %>%
  summarise(mean = mean(wd)) %>%
  ungroup()

# draw a boxplot of the mean versus treatment
ggplot(RATSL9S, aes(x = Group, y = mean)) +
  geom_boxplot() +
  stat_summary(fun = "mean", geom = "point", shape = 23, size = 4, fill = "white") +
  scale_y_continuous(name = "mean(wd), weeks 1-9")

# filter out the outlier 
RATSL9S1 <- RATSL9S %>% filter(mean < 580)

# draw a new boxplot of the mean versus treatment
ggplot(RATSL9S1, aes(x = Group, y = mean)) +
  geom_boxplot() +
  stat_summary(fun = "mean", geom = "point", shape = 23, size = 4, fill = "white") +
  scale_y_continuous(name = "mean(wd), weeks 1-9")
```

As the graphical material presented up to now have indicated that there is differences in the three treatments, let's confirm this by making a formal test for a difference. 

Let's apply a anova to assess any difference between the treatment groups, and also calculate a confidence interval for this difference. We use the data without the outlier created in the previous exercise. 

The anova confirms that there is statistically significant differences between at least two treatment groups. 

Baseline measurements of the outcome variable in a longitudinal study are often correlated with the chosen summary measure and using such measures in the analysis can often lead to substantial gains in precision when used appropriately as a covariate in an analysis of covariance. 

We can illustrate the analysis on the data using the WD value corresponding to time zero taken prior to the start of treatment as the baseline covariate. 

We see that the baseline WD is strongly related to the WD values taken after treatment has begun, and there is evidence of a treatment difference even after conditioning the baseline value.

```{r}
# perform a two-sample t-test
summary(aov(mean ~ Group, data = RATSL9S1))

# add the baseline from the original data as a new variable to the summary data
RATSL9S2 <- RATSL9S %>%
  mutate(baseline = RATS$WD1)

# fit the linear model with the mean as the response 
fit <- lm(mean ~ baseline + Group, data = RATSL9S2)

# compute the analysis of variance table for the fitted model with anova()
anova(fit)
```


## Part 2: BPRS data 

*2. Implement the analyses of Chapter 9 of MABS, using the R codes of Exercise Set 6: Meet and Repeat: PART II, but using the BPRS data (from Chapter 8 and Meet and Repeat: PART I). (0-8 points: 0-4 points for graphs or analysis results + 0-4 points for their interpretations)*

BPRS data, in which 40 male subjects were randomly assigned to one of two treatment groups and each subject was rated on the brief psychiatric rating scale (BPRS) measured before treatment began (week 0) and then at weekly intervals for eight weeks. The BPRS assesses the level of 18 symptom constructs such as hostility, suspiciousness, hallucinations and grandiosity; each of these is rated from one (not present) to seven (extremely severe). The scale is used to evaluate patients suspected of having schizophrenia.

Lets start by reading in the data and converting the categorical variables to factors.

```{r}
# read in data 
BPRSL <- read.csv("C:/Users/koivusus/IODS/IODS-project_new/data/BPRSL.csv")

# convert categoricals to factors 
BPRSL$treatment <- factor(BPRSL$treatment)
BPRSL$subject <- factor(BPRSL$subject)

# take a glimpse at the data
glimpse(BPRSL)
```

Let's start by visualizing the data. 

To begin, we will ignore the repeated-measures structure of the data and assume that all the observations are independent of one another. 

Now if we simply ignore that the sets of 8 bprs values come from the subject, we have a data set consisting of 360 bprs, weeks, and treatment that we see can easily be analyzed using multiple linear regression. 

To begin, we will plot the data, identifying the observations in each group but ignoring the longitudinal nature of the data.

```{r}
# load library
library(ggplot2)

# Plot the BPRS data
ggplot(BPRSL, aes(x = week, y = bprs, linetype = subject, col = subject)) +
  geom_line() +
  scale_linetype_manual(values = rep(1:10, times = 4)) +
  facet_grid(. ~ treatment, labeller = label_both) +
  theme(legend.position = "none") + 
  scale_y_continuous(limits = c(min(BPRSL$bprs), max(BPRSL$bprs)))
```

Continuing to ignore the repeated-measures structure of the data, we will fit a multiple linear regression model with bprs as response and `week` and `treatment` as explanatory variables. Week seems to have a statistically significant effect on bprs but treatment not. 

```{r}
# create a regression model 
BPRS_reg <- lm(bprs ~ week + treatment, data = BPRSL)

# print out a summary of the model
summary(BPRS_reg)
```

The previous model assumes independence of the repeated measures of bprs, and this assumption is highly unlikely. So, now we will move on to consider both some more appropriate graphics and appropriate models.

To begin the more formal analysis of the bprs data, we will first fit the *random intercept model* for the same two explanatory variables: `week` and `treatment`. Fitting a random intercept model allows the linear regression fit for each subject to differ in *intercept* from other subjects.

Based on the standard deviation of the subject, it seems like our random effect explains a relatively small amount of the overall standard deviation in the model. 

```{r}
# install lme4 package if its not yet installed
#install.packages("lme4)

# load library
library(lme4)

# Create a random intercept model
BPRS_ref <- lmer(bprs ~ week + treatment + (1 | subject), data = BPRSL, REML = FALSE)

# Print the summary of the model
summary(BPRS_ref) # pay attention to variability (standard deviation) of the subject
```

Now we can move on to fit the *random intercept and random slope model* to the BRPS data. Fitting a random intercept and random slope model allows the linear regression fits for each individual to differ in intercept but also in slope. This way it is possible to account for the individual differences in the subjects bprs values, but also the effect of time.

Based on the comparison of the two models (anova), the model with random intercept and random slope is statistically significantly better than the model with subject as an random effect., 

```{r}
# create a random intercept and random slope model
BPRS_ref1 <- lmer(bprs ~ week + treatment + (week | subject), data = BPRSL, REML = FALSE)

# print a summary of the model
summary(BPRS_ref1)

# perform an ANOVA test on the two models
anova(BPRS_ref1, BPRS_ref)
```

Finally, we can fit a random intercept and slope model that allows for a treatment Ã— week interaction. 

Compute the analysis of variance tables of the models `RATS_ref2` and `RATS_ref1`. Again pay attention to the likelihood ratio test chi-squared value and the according p-value. The lower the value the better the fit against the comparison model.

```{r}
# create a random intercept and random slope model with the interaction
BPRS_ref2 <- lmer(bprs ~ week + treatment + (week | subject) + week * treatment, data = BPRSL, REML = FALSE)

# print a summary of the model
summary(BPRS_ref2)

# perform an ANOVA test on the two models
anova(BPRS_ref2, BPRS_ref1)

# add T1_ and T2_ to te beginning of each row in the subject column based on whether it belongs treatment 1 or 2 in treatment column
BPRSL <- BPRSL %>%
  mutate(subject = ifelse(treatment == 1, paste0("T1_", subject), paste0("T2_", subject)))

# plot with colors showing the treatment groups
ggplot(BPRSL, aes(x = week, y = bprs, group = subject, col = treatment)) +
  geom_line(aes(linetype = treatment)) +
  scale_color_manual(values = c("darkgreen", "darkblue"))+
  scale_x_continuous(name = "Week", breaks = seq(0, 8, 1)) +
  scale_y_continuous(name = "BPRS") +
  theme(legend.position = "top")

# create a vector of the fitted values
Fitted <- fitted(BPRS_ref2)

# create a new column fitted 
BPRSL <- BPRSL %>% mutate(Fitted = Fitted)

# draw the plot with the Fitted values of weight
ggplot(BPRSL, aes(x = week, y = Fitted, group = subject, col = treatment)) +
  geom_line(aes(linetype = treatment)) +
  scale_color_manual(values = c("darkgreen", "darkblue"))+
  scale_x_continuous(name = "Week", breaks = seq(0, 8, 1)) +
  scale_y_continuous(name = "BPRS") +
  theme(legend.position = "top")
```
